This tutorial explains how to test Jason agents in AgentSpeak, using a novel (as of 2022)
goal-oriented test feature that enables an agent-oriented perspective on automated software testing
and test-driven development. The feature allows writing test programs for Jason agents in
AgentSpeak, and aligns software testing and agent-oriented programming abstractions. This
consolidation of perspectives is called _Goal-Oriented Test-Driven Development_ (GOTDD).

== What is Goal-Oriented Test-Driven Development?
In modern software development, testing plays a key role, as it helps ensure the software works as
expected. Ideally, developers use _Test-Driven Development_ (TDD) approaches, in which a large
portion of the tests is written during or even ahead of the implementation of the actual program
code. The assumption is that specifying the exact desired behavior of a software component _before_
implementing this component facilitates a more rigorous assessment of the component and ensures
testing is not cut short because of time shortage caused by mis-estimations. Generally, it is
considered good practice to focus automated testing efforts on _unit tests_ of small components that
can and hence _should_ be tested in a rigorous manner and to cover the overall system (or system of
systems) with less dense _integration tests_ and _End-to-End_ (E2E) tests; the latter cannot cover
all possible input and environment configurations because of the explosion in combinatorial options
(even for fairly small systems) but they can potentially catch unexpected behavior of components
that seemingly work correctly from a lower-level perspective.

From an agent-oriented perspective, unit tests cover behavior that is _agent-agnostic_, _i.e._ which
can be tested as if it was a function/method call -- for example, given the internal state the agent
-- and which is disconnected from the state of the environment and the other agents that (inter)act
in it. While unit tests for agents are conceptually not different from traditional unit tests,
Jason's GOTDD feature is novel even on this level because it provides first-class abstractions for
tests in an agent-oriented programming language. Still, more interestingly, Jason allows for the
specification of tests that check whether an agent, given an initial environment state (and
potentially given other agents), will eventually (or given a specific time constraint) achieve a
particular _goal_; _i.e._, goals are promoted to first-class abstractions for test-driven
development, which allows for integration tests for single agents (agent-environment integration)
and multi agents (agent-environment-agent, whereby the environment may or may not contain explicitly
modelled artifacts) integration. The figure below shows the _test pyramid_ from a traditional
software engineering perspective and contrasts it with an agent-oriented test pyramid.

image:./figures/Agent-Oriented_TDD.png[]

The tutorial below provides examples of unit testing, single agent testing, and multi-agent testing
with Jason. Note that E2E tests are not covered, because these are typically implemented in a
different technology ecosystem (for example: _Selenium_ for end-to-end user interface testing).
However, we consider E2E MAS testing an interesting open challenge that needs more exploration.

== Under the Hood
Under the hood, Jason's GOTDD feature allows for the instantiation of one main agent per test file,
as well as for the instantiation of several _mock agents_; in addition to mock agents, the main
(to-be-tested) agent may interact with other agents that have been implemented in a traditional
manner. The main agent is monitored by Jason's tester agent with regards to the main agent's ability
to achieve certain goals, or the agent's internal state (for example: belief adoption). Whenever
a corresponding assertion fires, the tester agent reports the result (pass or fail). 

image:./figures/Agents-TDD-overview.png[]

== Test Levels in Jason
Now, let us provide examples how tests on the three lower levels (_unit_, _single agent_, _multi
agent_, assuming that end-to-end tests need to be supported by additional tooling) work.
For explanatory purposes, we provide three examples for single-agent testing: a simple example, a
slightly more advanced example, and an example where the agent interacts with an artifact. Each
example builds upon its predecessor.

=== Project Setup
Let us set up our Jason project and configure it for GOTDD.

1. First, we create a mas2j project file and specify the infrastructure type, our agents, and the
ASL source paths (see below for the unit testing example):

[source]
----
MAS tdd {

    infrastructure: Centralised

    agents:
        xor;

    aslSourcePath:  "src/test/jason/inc";
                    "src/test/jason/asl";
                    "src/asl";
                    "src/agt";
                    "inc";
                    "$jasonJar/test/jason/inc";
}
----
Then, we create the source directory structure for our project:

[source]
----
/
- src
    - agt
- test
    - jacamo
        - agt
----

As a final setup step, we create a gradle build file that allows us to test our project.
We can simply copy and adjust the file we find
link:./1_room_agent_on_jason-jacamo/build.gradle[here]. We can also create a `logging.properties`
file such as this one link:./1_room_agent_on_jason-jacamo/logging.properties[here]. 
The setup is specific to the first example (unit testing); the setup for the other test examples
differs slightly. Take a look at the example sources to make sure your setup is correct.


=== Unit Testing in Jason
Let us start by implementing a unit test that tests a simple inference rule. At `src/agt`, we
create the file `room_agent.asl` and add the following rule:

[source]
----
now_is_warmer_than(T) :- temperature(C) & C > T.
----

As we can see, the rule checks if the current `temperature` is higher than some specifically
provided value. Because we merely draw inferences, but do not act in the environment, we consider
this scenario a *unit testing* scenario and not a single agent testing scenario.

Now, we set a temperature value:

[source]
----
temperature(15).
----

Finally, we try out our inference rule:

[source]
----
!auto_test.

+!auto_test:
    temperature(C)
    <- 
    .print("Current temperature: ",temperature(C));

    .eval(X1, now_is_warmer_than(20));
    .print(now_is_warmer_than(20)," = ",X1);

    .eval(X2, now_is_warmer_than(10));
    .print(now_is_warmer_than(10)," = ",X2);

    .eval(X3, now_is_warmer_than(15));
    .print(now_is_warmer_than(15)," = ",X3);
----

Such *naive* inline tests are frequently used to facilitate debugging, but have obvious
shortcomings:

* They do not allow for a clear separation between test and production code.
* They do not clearly describe desired behavior.
* They make it hard to automate tests.

To test the file properly, we create the file `test_room_agent.asl` at `src/test/jacamo/agt`. At the
beginning of this file, we import the Jason tester agent, as well as the file that we want to test:

[source]
----
{ include("tester_agent.asl") }
{ include("room_agent.asl") }
----

Then, we add a test goal, using the `@[test]` annotation:

[source]
----
@[test]
+!test_now_is_warmer_than
    <-
    !assert_false(now_is_warmer_than(20));
    !assert_true(now_is_warmer_than(10));
    !assert_false(now_is_warmer_than(15));
.
----

As we can see, the test specifies the truth table of the inference rule, given the following three
scenarios:

1. The provided value temperature is higher than the current temperature.
2. The provided value is lower than the current temperature.
3. The provided value is equal to the current temperature.

The complete project is available link:./1_room_agent/[here].


=== Single Agent Testing in Jason
In the following single agent testing example, we have a mock cooler agent that cools a room if the
temperature in the room is higher than some specific threshold, _i.e._, the agent *reacts* on
temperature changes, whereas its actions in turn **affect** the temperature in the room.

At `src/agt`, we create the file `cooler.asl` and again add our `now_is_warmer_than` inference rule:

[source]
----
now_is_warmer_than(T) :- temperature(C) & C > T.
----

Now, we implement the cooler functionality that starts the cooler if the temperature is above the
threshold:

[source]
----
+!temperature(T): 
	now_is_warmer_than(T) &
	temperature(C)
	<-  
	if (not cooling) {
	    /**
	 	 * To control the room temperature it could  
     	 * activate a physical cooler here
	 	 */
        +cooling;
		.log(warning,C," is too hot -> cooling until ",T);
    }
	!temperature(T);
.
----


Analogously, the cooler should stop cooling if the temperature is below the threshold:

[source]
----
+!temperature(T):
	cooling
	<-  
	.log(warning,"Temperature achieved: ",T);

    /**
	 * Deactivating the cooler
	 */
    -cooling;

    !temperature(T);
----

Let us highlight that our cooler example is simplistic from a real-world perspective, as we ignore
the control-theoretical nature of the problem.

Finally, we ensure that the cooler is continuously evaluating and adjusting its behavior, using the
following loop:

[source]
----
+!temperature(T)
    <-
    !temperature(T);
.
----

Note that in this example, we specify the initial beliefs of the agent in the
link:./2_cooler_agent_on_jason-jacamo/tdd.mas2j[mas2j file].

[source]
----
agents:
    room_agent [
        goals="temperature(10)",
        beliefs="temperature(15)"
    ];
----

To test the agent, we create the file `test_room_agent.asl` at `src/test/jacamo/agt` and test the
`test_now_is_warmer_than` inference rule, like in the first example:

[source]
----
@[test]
+!test_now_is_warmer_than
    <-
    !assert_false(now_is_warmer_than(20));
    !assert_true(now_is_warmer_than(10));
    !assert_false(now_is_warmer_than(15));
.
----

Also, we want to test whether the agent *acts* correctly. For this, set at target temperature of 10
degrees (given a current temperature of 15 degrees) and regularly check in a loop whether
the cooler acts as expected given the current temperature and the agents's goal:

[source]
----
@[test]
+!test_cool_until_temperature_dropping
    <-
    -+temperature(15); // The default current temperature is 15 degrees
    !!temperature(10); // We want to reach 10 degrees (this is running in parallel)
    .wait(50); // Give some time to the agent to react
    for ( .range(I,1,10) ) { // Let us check 10x if it is cooling correctly
        ?temperature(C);
        if (C > 10) { // Greater than 10, cooler MUST be on
            !assert_true(cooling);
            -+temperature(C-1); // emulate that the temperature has dropped
        } else { // Not greater than 10, cooler MUST be off
            !assert_false(cooling);
        }
    }
    .drop_desire(temperature(10));
----

In addition, we simulate arbitrary temperature decreases using a random number generator and check
if the cooler exhibits expected behavior in these scenarios. For reproducibility purposes, we set a
fixed random seed so that the test always yields the same result. For this we make use of Jason's
link:http://jason.sourceforge.net/api/jason/stdlib/random.html/[`random`] and
link:http://jason.sourceforge.net/api/jason/stdlib/set_random_seed.html[`set_random_seed`]
functions.

[source]
----
@[test]
+!test_cool_until_random_temperature
    <-
    -+temperature(18); // Let us say the temperature is 18 degrees
    !!temperature(20); // We want to reach 20 degrees (this is running in parallel)
    .set_random_seed(1); // Make sure this test will be always the same
    .wait(50); // Give some time to the agent to react
    for ( .range(I,1,20) ) { // Let us check 20x if it is cooling correctly
        ?temperature(C);
        if (C > 20) { // Greater than 20, cooler MUST be on
            !assert_true(cooling);
            .random(X); // Emulate that the temperature has dropped
            -+temperature( C - math.ceil(X*2) );
        } else { // Not greater than 20, cooler MUST be off
            !assert_false(cooling);
            .random(X); // Emulate that the temperature has risen
            -+temperature( C + math.ceil(X*2) );
        }
    }
    .drop_desire(temperature(20)); // dropping the desire that is running in parallel
.
----


The complete project is available link:./2_room_agent_cooling/[here].

==== Extended Single-Agent Testing Example
In this example, we extend the cooler agent and turn it into an air conditioner that can both cool
and heat. For this, we first defined a tolerance threshold (set to 0.4 degrees) and two additional
rules: one to check if the temperature is in a particular range and one to check whether the current
temperature is colder than a given temperature value. In contrast to the rule in the previous
example, our rules now consider the tolerance threshold.

[source]
----
tolerance(0.4).

temperature_in_range(T)
	:- not now_is_colder_than(T) & not now_is_warmer_than(T).

now_is_colder_than(T)
	:- temperature(C) & tolerance(DT) & (T - C) > DT.

now_is_warmer_than(T)
	:- temperature(C) & tolerance(DT) & (C - T) > DT.
----

Then, we add heating behavior in addition to the already implemented cooling functionality:

[source]
----
+!temperature(T): 
	now_is_warmer_than(T) &
	temperature(C)
	<-  
	if (not status(cooling)) {
	    /**
	 	 * To control the room temperature it could  
     	 * activate a physical cooler here
	 	 */
        -+status(cooling);
		.log(warning,C," is too hot -> cooling until ",T);
    }
	!temperature(T);
.

+!temperature(T): 
	now_is_colder_than(T) &
	temperature(C)
	<-  
	if (not status(heating)) {
	    /**
	 	 * To control the room temperature it could  
     	 * activate a physical cooler here
	 	 */
        -+status(heating);
		.log(warning,C," is too hot -> cooling until ",T);
    }
	!temperature(T);
.
----

Finally, we implement behavior that checks whether the temperature is within the tolerance range
and, if so, sets the air conditioner to idle (we also trigger the deliberation loop).

[source]
----
+!temperature(T):
	temperature_in_range(T)
	<-  
	if (not status(idle)) {
    	/**
	 	 * Deactivating the HVAC
	  	 */
    	-+status(idle);
		.log(warning,"Temperature achieved: ",T);
	}
    !temperature(T);
.

+!temperature(T)
    <-
    !temperature(T);
.

{ include("$jacamoJar/templates/common-cartago.asl") }
{ include("$jacamoJar/templates/common-moise.asl") }
----

Again, we we create our test file `test_room_agent.asl` at `src/test/jacamo/agt`. First, we test
all inference rules.
Note that the tests now also consider the tolerance range.

[source]
----
/**
 * Testing rules: now_is_colder_than, now_is_warmer_than and
 * temperature_in_range
 */
@[test]
+!test_temperature_rules
    <-
    -+tolerance(0.4);
    -+temperature(15);
    !assert_false(now_is_colder_than(-5));
    !assert_false(now_is_colder_than(14));
    !assert_false(now_is_colder_than(14.8)); // in the tolerance range
    !assert_false(now_is_colder_than(15.2)); // in the tolerance range
    !assert_true(now_is_colder_than(15.5));
    !assert_true(now_is_colder_than(16));
    !assert_true(now_is_colder_than(40));

    !assert_true(now_is_warmer_than(-5));
    !assert_true(now_is_warmer_than(14));
    !assert_false(now_is_warmer_than(14.8)); // in the tolerance range
    !assert_false(now_is_warmer_than(15.2)); // in the tolerance range
    !assert_false(now_is_warmer_than(15.5));
    !assert_false(now_is_warmer_than(16));
    !assert_false(now_is_warmer_than(40));

    !assert_false(temperature_in_range(-5));
    !assert_false(temperature_in_range(14));
    !assert_true(temperature_in_range(14.8)); // in the tolerance range
    !assert_true(temperature_in_range(15.2)); // in the tolerance range
    !assert_false(temperature_in_range(15.5));
    !assert_false(temperature_in_range(16));
    !assert_false(temperature_in_range(40));
.
----

Now, we can test cooling and heating functionality. Because the tests for the cooling functionality
have already been introduced in the previous example and heating and cooling work analogously, we
only provide the heating tests here (however, all tests are available in the
link:./2_room_agent_also_heating/src/test/jacamo/agt/test_room_agent.asl[test file]).  We set at
target temperature of 28 degrees (given a current temperature of 22 degrees) and regularly check in
a loop whether the agent acts as expected given the current temperature and the agents's goal:


[source]
----
@[test]
+!test_heat_until_temperature_rising
    <-
    -+temperature(22); // Let us say the temperature is 22 degrees
    !!temperature(28); // We want to reach 28 degrees (this is running in parallel)
    .wait(50); // Give some time to the agent to react
    for ( .range(I,1,10) ) { // Let us check 10x if it is cooling correctly
        ?temperature(C);
        .wait(10);
        if (now_is_colder_than(28)) {
            !assert_true(status(heating));
            -+temperature(C+1); // Emulate that the temperature has risen
        } else { 
            !assert_false(status(heating));
        }
    }
    .drop_desire(temperature(28)); // dropping the desire that is running in parallel
.
----

Then, we test the heating functionality with randomly generated temperature effects (within a
range), using a random seed, as in the previous example:

[source]
----
@[test]
+!test_heat_until_random_temperature
    <-
    -+temperature(18); // Let us say the temperature is 18 degrees
    !!temperature(25); // We want to reach 25 degrees (this is running in parallel)
    .set_random_seed(2); // Make sure this test will be always the same
    .wait(50); // Give some time to the agent to react
    for ( .range(I,1,20) ) { // Let us check 20x if it is cooling correctly
        ?temperature(C);
        .wait(10);
        if (now_is_colder_than(25)) {
            !assert_true(status(heating));
            .random(X); // Emulate that the temperature has risen
            -+temperature( C + math.ceil(X*2) );
        } else {
            !assert_false(status(heating));
            .random(X); // Emulate that the temperature has dropped
            -+temperature( C - math.ceil(X*2) );
        }
    }
    .drop_desire(temperature(25)); // dropping the desire that is running in parallel
.
----

The complete project is available link:./3_room_agent_also_heating/[here].


=== Agents and Artifacts
In this final single-agent testing example, we introduce an artifact that our agent interacts with.
In this (as well as the next) example, we run the multi-agent system using
link:https://github.com/jacamo-lang/jacamo-rest[jacamo-rest] and
link:https://github.com/jacamo-lang/jacamo-web[jacamo-web]. However, for our testing example, this
is merely a configuration detail that does not affect the implementation and testing concept. First,
we configure the MAS in the file `tdd.jcm`:

[source]
----
mas tdd {
    agent room_agent {
        goals: temperature(21)
        focus: room.hvac
    }

    workspace room {
        artifact hvac: devices.HVAC(15)
    }

    asl-path: src/agt
              src/agt/inc
              
    platform:   jacamo.web.JCMWeb("--main 2181 --restPort 8080") // zookeeper & restPort
}
----
As we can see, our room agent focuses the `hvac` (air conditioning) artifact and has a particular
target temperature (21Â°C) as its goal. The `platform` property configures jacamo-web (which, in
turn, uses jacamo-rest).

The artifact models the air conditioning/HVAC. It has the following methods:

* `init` (with _temperature_ parameter): sets the initial temperature and sets the HVAC's state to
`idle`.

* `updateTemperatureProc` (internal (private), with _step_ parameter): while the HVAC is not in
state `idle`, increases the temperature by `step` degrees and waits for 100ms to then repeat the
loop.

* `startHeating`: sets the state to `heating` and calls `updateTemperatureProc` with _step_ set to
`0.5`.`

* `startCooling`: sets the state to `cooling` and calls `updateTemperatureProc` with _step_ set to
`-0.5`.

* `stopAirConditioner`: sets the state of the HVAC to `idle`.

The source code of the artifact looks as follows:

[source]
----
package devices;

import cartago.*;

@ARTIFACT_INFO(outports = { @OUTPORT(name = "out-1") })

public class HVAC extends Artifact {

    void init(double initialTemperature){
        defineObsProperty("state","idle");
        defineObsProperty("temperature",initialTemperature);
        log("Temperature: "+getObsProperty("temperature").doubleValue());
    }

    @OPERATION void startHeating(){
        log("startHeating");
        getObsProperty("state").updateValue("heating");
        this.execInternalOp("updateTemperatureProc",0.5);
    }

    @OPERATION void startCooling(){
        log("startCooling");
        getObsProperty("state").updateValue("cooling");
        this.execInternalOp("updateTemperatureProc",-0.5);
    }

    @OPERATION void stopAirConditioner(){
        log("stopAirCond");
        getObsProperty("state").updateValue("idle");
    }

    @INTERNAL_OPERATION void updateTemperatureProc(double step){
        ObsProperty temp = getObsProperty("temperature");
        ObsProperty state = getObsProperty("state");
        while (!state.stringValue().equals("idle")){
            temp.updateValue(temp.doubleValue() + step);
            log("Temperature: "+temp.doubleValue());
            this.await_time(100);
        }
    }
}
----

Then, we integrate the artifact with our agent, replacing the hard-coded cooling and heating
emulation with actions upon the HVAC artifact:

[source]
----
+!temperature(T): 
	now_is_warmer_than(T) &
	temperature(C)
	<-  
	if (not status(cooling)) {
	    startCooling;
        -+status(cooling);
		.log(warning,C," is too hot -> cooling until ",T);
    }
	!temperature(T);
.

+!temperature(T): 
	now_is_colder_than(T) &
	temperature(C)
	<-  
	if (not status(heating)) {
	    startHeating;
        -+status(heating);
		.log(warning,C," is too hot -> cooling until ",T);
    }
	!temperature(T);
.

+!temperature(T):
	temperature_in_range(T)
	<-  
	if (not status(idle)) {
    	stopAirConditioner;
    	-+status(idle);
		.log(warning,"Temperature achieved: ",T);
	}
    !temperature(T);
.
----

When adjusting the tests of the previous example to support the agent-artifact integration, we first


[source]
----
/* call plans that in itself are not annotated as tests */
@[test]
+!test_temp_control
    <-
    !test_cool_until_temperature_dropping;
    !test_cool_until_random_temperature;
    !test_heat_until_temperature_rising;
    !test_heat_until_random_temperature;
    !!test_results;
.

/*meta event: occurs */
^!test_cool_until[state(finished)]
    <-
    ?temperature(C);
    +cooling_finished_with(C);
.

+!test_results
    <-
    .wait(100);
    !assert_true(heating_finished_with(_));
    !assert_true(cooling_finished_with(_));
    ?heating_finished_with(HT);
    ?cooling_finished_with(CT);
    ?tolerance(DT);
    !assert_equals(25,HT,DT);
    !assert_equals(21,CT,DT);
.

----



[source]
----

/**
 * Test heater when the temperature is rising from a cold condition to the target
 */
+!test_heat_until_temperature_rising
    <-
    /**
     * Add mock plans to do not call the artifact.
     * It produces a mocked answer. The belief status(X) 
     * is being used to assert whether is is correct
     */
    .add_plan({ 
    +!temperature(T): 
    	now_is_colder_than(T) &
    	temperature(C)
    	<-  
    	if (not status(heating)) {
	        /*startHeating;*/
            -+status(heating);
		    .log(warning,C," is too hot -> cooling until ",T);
        }
	    !temperature(T);
    }, self, begin);

    .add_plan({ 
    +!temperature(T):
    	temperature_in_range(T)
    	<-  
    	if (not status(idle)) {
    	    /*stopAirConditioner;*/
    	    -+status(idle);
		    .log(warning,"Temperature achieved: ",T);
	    }
        !temperature(T);
    }, self, begin);

    -+temperature(22); // Let us say the temperature is 22 degrees
    !!temperature(28); // We want to reach 28 degrees (this is running in parallel)
    .wait(50); // Give some time to the agent to react
    for ( .range(I,1,10) ) { // Let us check 10x if it is cooling correctly
        ?temperature(C);
        .wait(10);
        if (now_is_colder_than(28)) {
            !assert_true(status(heating));
            -+temperature(C+1); // Emulate that the temperature has risen
        } else { 
            !assert_false(status(heating));
        }
    }
    .drop_desire(temperature(28)); // dropping the desire that is running in parallel
.
----

The complete project is available link:./4_room_agent_with_artifact/[here].

=== Multiple Agents and Agents on the Web
Finally, let us implement and test a simple Multi-Agent System (MAS). In the MAS, we have an
additional _assistant agent_ that relays user preferences to the room agent. Accordingly, the code
for the assistant agent is very simple:

[source]
----
+!send_preference:
    preferred_temperature(T) &
    recipient_agent(R)
    <-
    .log(warning,"Sending preference for ",T);
    .send(R,achieve,add_preference(T));
.

{ include("$jacamoJar/templates/common-cartago.asl") }
{ include("$jacamoJar/templates/common-moise.asl") }
----

Note that in the `tdd.jcm` configuration file, we then instantiate two assistant agents representing
the users _Cleber_ and _Tim_, respectively:

[source]
----
agent tims_assistant : assistant.asl {
        beliefs: preferred_temperature(23)
                 recipient_agent(room_agent)
        goals: send_preference
    }

agent clebers_assistant : assistant.asl {
    beliefs: preferred_temperature(25)
                recipient_agent(room_agent)
    goals: send_preference
}
----

Then, we adjust our room agent so that it considers all preferences received by the assistant agents
to then set its goal temperature to the average of the agents' temperature preferences (of course,
this approach invites strategic manipulation by the users, but let us ignore this issue for the
sake of simplicity):

[source]
----
+!add_preference(T)[source(S)]
    <-
    .abolish(preference(S,_));
    +preference(S,T);
    .findall(X,preference(_,X),L);
    .drop_desire(temperature(_));
    !temperature(math.average(L));
.
----

Now, we can test our agent. However, before we can write the actual tests, we first want to create
some mocks. Note that we have already worked with _mock plans_ in the previous example. These plans
were simply provided alongside the test code. To allow for a better separation of concerns and with
the ultimate objective of facilitating test readability and maintainability, we move all mocks to
specific files (in the `inc` folder).
First, we implement a mock plan base for our room agent (in the file `mock_plans.asl`):

[source]
----
+!add_mock_plans_room_agent
    <-
    .add_plan({ 
    +!temperature(T): 
        now_is_warmer_than(T) &
        temperature(C)
        <-  
        if (not status(cooling)) {
            /*Mock removing the external action startCooling;*/
            -+status(cooling);
            .log(warning,C," is too hot -> cooling until ",T);
        }
        !temperature(T);
    }, self, begin);

    .add_plan({ 
    +!temperature(T): 
        now_is_colder_than(T) &
        temperature(C)
        <-  
        if (not status(heating)) {
            /*Mock removing the external action startHeating;*/
            -+status(heating);
            .log(warning,C," is too hot -> cooling until ",T);
        }
        !temperature(T);
    }, self, begin);
    
    .add_plan({ 
    +!temperature(T):
        temperature_in_range(T)
        <-  
        if (not status(idle)) {
            /*Mock removing the external action stopAirConditioner;*/
            -+status(idle);
            .log(warning,"Temperature achieved: ",T);
        }
        !temperature(T);
    }, self, begin);

    .add_plan({ 
    +!add_preference(T)[source(S)]
        <-
        .abolish(preference(S,_));
        +preference(S,T);
        .findall(X,preference(_,X),L);
        /*Mock temperature with the average*/
        +temperature(math.average(L));
    }, self, begin);
.
----

As we can see, the mock plans do not make calls to the artifact and hence allow (multi-)agent
testing without artifact instantiation. Also, we need to implement some generic mock helpers
(in `mock_helpers.asl`) that allow us to achieve the following:

* Retrieve an agent's _achievement plan triggers_ (starting with `+!`):

[source]
----
+?retrieve_achievement_plans(Plans) : 
.relevant_plans({+!_},LP,LL) 
<- 
.findall(T, .member(P,LP) & P = {@L +!T : C <- B} & Label = L, Plans);
.
----

* Retrieve an agent's _add belief plan triggers_ (starting with `+!`):

[source]
----
+?retrieve_add_belief_plans(Plans) : 
    .relevant_plans({+_},LP,LL) 
    <- 
    .findall(T, .member(P,LP) & P = {@L +T : C <- B} & Label = L, Plans);
.
----

* Check if a plan is an _achievement plan_ or not:

[source]
----
+?is_achievement_plan(P,X) 
    <- 
    ?retrieve_achievement_plans(L); 
    .eval(X,.member(P,L));
.
----

These features are useful for checking if one agent's communication with another agent has the
expected effects on the latter agent. They are, essentially, extensions of the Jason library's
testing utilities (version 3.1) and may make it into the Jason core eventually.


Also, we implement functionality in `tester_helpers.asl` that allows us to start mock agents:

[source]
----
+!start_mock_agent(MockAgName, File) :
    .my_name(ME)
    <-
    .create_agent(MockAgName, File);
    .send(MockAgName, tell, mock_owner(ME));
    // if the mock was already sleeping, wait it wake up first
    .wait( not sleeping(MockAgName), 300, _ );
    // wait the mock finish some task and tell that it is now sleeping
    .wait( sleeping(MockAgName) );
.   
----

Now, we can implement our mock agents. The mock assistant agent (`mock_assistant.asl`) is
essentially a copy of the actual assistant agent, but features the mock helper utilities:

[source]
----
{ include("mock_helpers.asl") }
{ include("mock_agent.asl") }

{ include("assistant.asl") }
----

In contrast, the mock room agent (`mock_room_agent.asl`) also loads the mock plans that we have
specified in `mock_plans.asl`:

[source]
----
{ include("mock_helpers.asl") }
{ include("mock_agent.asl") }
{ include("mock_plans.asl") }
/**
 * This agent includes the code of the agent under tests
 */
{ include("room_agent.asl") }

!add_mock_plans_room_agent.
----

Finally, we can implement the actual tests. In our example, we test all of the newly implemented
functionality from the perspective of the assistant agent (in `test_assistant.asl`). First, we
tests whether we can successfully send our temperature preference to other agents:

[source]
----
@[test]
+!test_send_preference
    <-
    +preferred_temperature(23);
    +recipient_agent(test_assistant);
    !send_preference;
.

+!add_preference(T)[source(S)]:
    preferred_temperature(TT)
    <-
    !assert_equals(TT,T);
    !assert_equals(self,S);
.
----

Then, we test the compatibility between the assistant agent and the room agent. In particular, we
test whether the room agent has plans that are triggered when the `.send` command has been executed
by the assistant agent. The test involves the instantiation of a mock room agent. This allows us to
inspect the agent's _achievement plans_:s
[source]
----
@[test]
+!test_compatibility
    <-
    !start_mock_agent(mock_room_ag, "mock_room_agent.asl");
    !is_achievement_plan(mock_room_ag,add_preference(_),X);
    !assert_true(X);
    !is_achievement_plan(mock_room_ag,non_existing_plan(_,_),Y);
    !assert_false(Y);
    .kill_agent(mock_room_ag);
.
----

Finally, we test whether the room agent aggregates the preferences of several assistant agents
correctly. Again, this is achieved by instantiating mock agents, this time two assistants with
different temperature preferences and one mock room agent.
[source]
----
@[test]
+!test_multiple_preferences
    <-
    /* 
     * Create a room_agent and two assistants. The assistants
     * ask for 23 and 25 degrees, so the final temperature should
     * be 24 degrees.
     */
    !start_mock_agent(mock_room_agent, "mock_room_agent.asl");
    !start_mock_agent(tims_assistant, "mock_assistant.asl");
    !start_mock_agent(clebers_assistant, "mock_assistant.asl");

    .send(tims_assistant,tell,preferred_temperature(23));
    .send(tims_assistant,tell,recipient_agent(mock_room_agent));
    .send(tims_assistant,achieve,send_preference);
    .send(clebers_assistant,tell,preferred_temperature(25));
    .send(clebers_assistant,tell,recipient_agent(mock_room_agent));
    .send(clebers_assistant,achieve,send_preference);

    /* 
     * Give some time to the room_agent process the information
     * and mocking a result
     */
    .wait(50);
    .send(mock_room_agent,askOne,temperature(T),temperature(T));
    !assert_equals(24,T);

    .kill_agent(mock_room_agent);
    .kill_agent(tims_assistant);
    .kill_agent(clebers_assistant);

.
----

The complete project is available link:./5_multi_agents/[here].

== Conclusion
This tutorial has provided a brief overview of how to test Jason agents directly in AgentSpeak, as
well as of the conceptual benefits goal-oriented test-driven development provides for the
development of multi-agent systems.
